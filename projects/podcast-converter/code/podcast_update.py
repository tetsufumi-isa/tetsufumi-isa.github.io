#!/usr/bin/env python3
"""
YouTubeâ†’ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¤‰æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆæ”¹è‰¯ç‰ˆï¼‰
----------------------------------------
æ©Ÿèƒ½ï¼š
1. YouTubeå†ç”Ÿãƒªã‚¹ãƒˆã‚„ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º
2. MP3å½¢å¼ã«å¤‰æ›ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã«ä¿å­˜
3. Cloudflare R2ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
4. æœŸé™åˆ‡ã‚Œãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã¨R2ã‹ã‚‰å‰Šé™¤
5. Apple Podcastå½¢å¼ã®RSSãƒ•ã‚£ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ
6. GitHubã«push
"""

import os
import subprocess
import json
import re
import glob
from datetime import datetime, timedelta
import email.utils
import boto3
from botocore.client import Config
import logging
import concurrent.futures
import time
import configparser
import sys
import threading

# ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
script_dir = os.path.dirname(os.path.abspath(__file__))
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾— (code ã®è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª)
project_dir = os.path.dirname(script_dir)  # codeã®1éšå±¤ä¸ŠãŒãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
# logs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹ã‚’ä½œæˆ
logs_dir = os.path.join(project_dir, "logs")
# logs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒãªã‘ã‚Œã°ä½œæˆ
os.makedirs(logs_dir, exist_ok=True)

# æ—¥ä»˜å½¢å¼ã®è¨­å®šï¼ˆYYYY-MM-DDï¼‰
today = datetime.now().strftime("%Y-%m-%d")
# æ—¥åˆ¥ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’ä½œæˆ
log_file = os.path.join(logs_dir, f"podcast_{today}.log")

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file, encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— (100æ—¥ä»¥ä¸Šå‰ã®ãƒ­ã‚°ã‚’å‰Šé™¤)
MAX_LOG_DAYS = 100
try:
    log_pattern = os.path.join(logs_dir, "podcast_*.log")
    for log_path in glob.glob(log_pattern):
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥ä»˜ã‚’æŠ½å‡º (podcast_YYYY-MM-DD.log)
            file_date_str = os.path.basename(log_path).replace("podcast_", "").replace(".log", "")
            file_date = datetime.strptime(file_date_str, "%Y-%m-%d")
            # 100æ—¥ä»¥ä¸Šå‰ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            if (datetime.now() - file_date).days > MAX_LOG_DAYS:
                os.remove(log_path)
                logger.info(f"å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {log_path}")
        except Exception as e:
            logger.error(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {log_path} - {e}")
except Exception as e:
    logger.error(f"ãƒ­ã‚°ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")

# ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ—¥æœ¬èªåŒ–é–¢æ•°
def translate_youtube_error(error_msg):
    """YouTubeã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ—¥æœ¬èªã«å¤‰æ›ã™ã‚‹"""
    if "Premieres in" in error_msg:
        days = re.search(r'in (\d+) days', error_msg)
        if days:
            return f"ğŸ“… ãƒ—ãƒ¬ãƒŸã‚¢å…¬é–‹å¾…ã¡ï¼ˆ{days.group(1)}æ—¥å¾Œï¼‰"
        else:
            return f"ğŸ“… ãƒ—ãƒ¬ãƒŸã‚¢å…¬é–‹å¾…ã¡"
    elif "Private video" in error_msg:
        return "ğŸ”’ éå…¬é–‹å‹•ç”»ã§ã™"
    elif "Video unavailable" in error_msg or "removed by the uploader" in error_msg:
        return "âŒ å‹•ç”»ãŒå‰Šé™¤ã•ã‚Œã¦ã„ã¾ã™"
    elif "This video is not available" in error_msg:
        return "â›” ã“ã®å‹•ç”»ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“"
    else:
        return f"âš ï¸ {error_msg}"  # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¯ãã®ã¾ã¾è¡¨ç¤º

# yt-dlpã®åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶é™ã™ã‚‹ãŸã‚ã®ã‚»ãƒãƒ•ã‚©
yt_dlp_semaphore = threading.Semaphore(2)  # æœ€å¤§2ã¤ã®yt-dlpãƒ—ãƒ­ã‚»ã‚¹ã‚’åŒæ™‚å®Ÿè¡Œ

# è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
def load_config():
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã‚’å–å¾—
    config_path = os.path.join(script_dir, 'config.ini')
    
    if os.path.exists(config_path):
        config = configparser.ConfigParser()
        config.read(config_path, encoding='utf-8')
        return config
    else:
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤ºã—ã¦çµ‚äº†
        error_msg = f"ã‚¨ãƒ©ãƒ¼: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« '{config_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"
        logger.error(error_msg)
        sys.exit(1)

# R2ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
def init_r2_client(config):
    session = boto3.session.Session()
    client = session.client(
        's3',
        region_name='auto',
        endpoint_url=config['R2']['endpoint'],
        aws_access_key_id=config['R2']['access_key'],
        aws_secret_access_key=config['R2']['secret_key'],
        config=Config(signature_version='s3v4')
    )
    return client

# R2ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
def upload_to_r2(client, local_path, remote_path, bucket):
    try:
        with open(local_path, 'rb') as f:
            client.upload_fileobj(f, bucket, remote_path, ExtraArgs={'ACL': 'public-read'})
        return True
    except Exception as e:
        logger.error(f"R2ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {e}")
        return False

# R2ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
def delete_from_r2(client, remote_path, bucket):
    try:
        client.delete_object(Bucket=bucket, Key=remote_path)
        return True
    except Exception as e:
        logger.error(f"R2å‰Šé™¤å¤±æ•—: {e}")
        return False

# R2å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
def list_r2_files(client, prefix, bucket):
    try:
        response = client.list_objects_v2(Bucket=bucket, Prefix=prefix)
        if 'Contents' in response:
            return [item['Key'] for item in response['Contents']]
        return []
    except Exception as e:
        logger.error(f"R2ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—å¤±æ•—: {e}")
        return []

# ç•ªçµ„å‡¦ç†é–¢æ•°
def process_program(args):
    folder_name, playlist_url, config, r2_client = args

    # ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ãƒãƒ£ãƒ³ãƒãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æŒ‡å®š
    data_dir = os.path.join(project_dir, "data")
    output_dir = os.path.join(data_dir, folder_name)
    os.makedirs(output_dir, exist_ok=True)

    r2_bucket = config['R2']['bucket']
    min_duration = int(config['Settings']['min_duration'])
    max_duration = int(config['Settings']['max_duration'])
    expire_days = int(config['Settings']['expire_days'])
    max_items = config['Settings'].get('max_items', '15')
    look_back_days = int(config['Settings'].get('look_back_days', '4'))

    # ç•ªçµ„åã‚’è¨­å®šã‹ã‚‰å–å¾—
    display_name = config['Channels'].get(folder_name, folder_name)

    logger.info(f"ğŸ™ï¸ ç•ªçµ„å‡¦ç†é–‹å§‹: {folder_name} ({display_name})")

    threshold_date = int((datetime.today() - timedelta(days=look_back_days)).strftime('%Y%m%d'))

    # å‹•ç”»ãƒªã‚¹ãƒˆå–å¾—
    try:
        result = subprocess.run([
            "yt-dlp", "--flat-playlist", "-J",
            "--playlist-items", f"1-{max_items}",
            playlist_url
        ], capture_output=True, text=True, check=True)

        playlist = json.loads(result.stdout)
        entries = playlist.get("entries", [])
        logger.info(f"ğŸï¸ å¯¾è±¡å‹•ç”»æ•°: {len(entries)}")
    except subprocess.CalledProcessError as e:
        logger.error(f"âŒ å‹•ç”»IDå–å¾—å¤±æ•—: {folder_name} - {translate_youtube_error(e.stderr)}")
        return
    except json.JSONDecodeError:
        logger.error(f"âŒ å‹•ç”»ãƒªã‚¹ãƒˆJSONãƒ‘ãƒ¼ã‚¹å¤±æ•—: {folder_name}")
        return
    except Exception as e:
        logger.error(f"âŒ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {folder_name} - {e}")
        return

    downloaded = 0
    durations = {}

    # æ—¢å­˜MP3ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆã™ã§ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã®å ´åˆã«ä½¿ç”¨ï¼‰
    for filename in os.listdir(output_dir):
        if filename.endswith(".mp3"):
            filepath = os.path.join(output_dir, filename)
            try:
                # ffprobeã§å‹•ç”»ã®é•·ã•ã‚’å–å¾—
                probe_result = subprocess.run([
                    os.path.join(config['Paths']['ffmpeg_path'], "ffprobe"),
                    "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "json",
                    filepath
                ], capture_output=True, text=True, check=True)

                probe_data = json.loads(probe_result.stdout)
                duration = float(probe_data['format']['duration'])
                durations[filename] = int(duration)
            except:
                # å–å¾—ã§ããªã„å ´åˆã¯æ¨å®šå€¤ã¨ã—ã¦1æ™‚é–“ã‚’è¨­å®š
                durations[filename] = 3600

    # å„å‹•ç”»ã‚’å‡¦ç†
    for entry in entries:
        if not entry or not entry.get("id"):
            continue
        video_id = entry["id"]
        url = f"https://www.youtube.com/watch?v={video_id}"

        try:
            meta = subprocess.run(["yt-dlp", "-J", url], capture_output=True, text=True, check=True)
            data = json.loads(meta.stdout)

            title = data.get("title")
            upload_date = data.get("upload_date")
            duration = data.get("duration")

            if not all([title, upload_date, duration]):
                logger.warning(f"âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {url}")
                continue

            if int(upload_date) < threshold_date:
                logger.debug(f"â­ï¸ å¤ã„å‹•ç”»ã‚’ã‚¹ã‚­ãƒƒãƒ—: {upload_date} < {threshold_date}")
                continue

            if not (min_duration <= duration <= max_duration):
                logger.debug(f"â­ï¸ é•·ã•æ¡ä»¶å¤–ã‚’ã‚¹ã‚­ãƒƒãƒ—: {duration}ç§’")
                continue

            mmdd = datetime.strptime(upload_date, "%Y%m%d").strftime("%m-%d")
            safe_title = "".join(c for c in title if c not in r'<>:"/\\|?*').replace("#", " ")
            filename = f"{mmdd}ï¼š{safe_title[:40]}.mp3"
            filepath = os.path.join(output_dir, filename)

            if os.path.exists(filepath):
                logger.info(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ï¼‰: {filename}")
                durations[filename] = duration
                continue

            logger.info(f"â¬‡ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {filename}")
            with yt_dlp_semaphore:  # ã‚»ãƒãƒ•ã‚©ã‚’ä½¿ç”¨ã—ã¦åŒæ™‚å®Ÿè¡Œæ•°ã‚’åˆ¶é™
                dl_result = subprocess.run([
                    "yt-dlp", "-x",
                    "--audio-format", "mp3",
                    "--ffmpeg-location", config['Paths']['ffmpeg_path'],
                    "--postprocessor-args", "-b:a 128k",
                    "-o", filepath,
                    url
                ], capture_output=True, text=True)

            if dl_result.returncode == 0:
                downloaded += 1
                durations[filename] = duration

                # R2ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                logger.info(f"â˜ï¸ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰: {filename}")
                remote_path = f"{folder_name}/{filename}"
                upload_success = upload_to_r2(r2_client, filepath, remote_path, r2_bucket)
                if not upload_success:
                    logger.warning(f"âš ï¸ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {filename}")
            else:
                logger.error(f"âš ï¸ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¤±æ•—: {title}\n{translate_youtube_error(dl_result.stderr)}")
        except subprocess.CalledProcessError as e:
            logger.error(f"âš ï¸ yt-dlpå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {translate_youtube_error(e.stderr)}")
            continue
        except json.JSONDecodeError:
            logger.error(f"âš ï¸ JSONãƒ‘ãƒ¼ã‚¹å¤±æ•—: {url}")
            continue
        except Exception as e:
            logger.error(f"âš ï¸ äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    logger.info(f"âœ… ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼ˆ{downloaded} ä»¶ï¼‰")

    # å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã¨R2ã®ä¸¡æ–¹ï¼‰
    logger.info(f"ğŸ§¹ å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤: {folder_name}")

    # R2ã®ç¾åœ¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—
    r2_files = list_r2_files(r2_client, f"{folder_name}/", r2_bucket)
    r2_filenames = [os.path.basename(path) for path in r2_files]

    for filename in os.listdir(output_dir):
        if filename.endswith(".mp3") and "ï¼š" in filename:
            try:
                mmdd = filename.split("ï¼š")[0]
                file_date = datetime.strptime(mmdd, "%m-%d").replace(year=datetime.now().year)

                # æ—¥ä»˜ãŒå¤ã„å ´åˆ
                if datetime.now() - file_date > timedelta(days=expire_days):
                    # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    local_path = os.path.join(output_dir, filename)
                    if os.path.exists(local_path):
                        os.remove(local_path)
                        logger.info(f"ğŸ—‘ï¸ ãƒ­ãƒ¼ã‚«ãƒ«å‰Šé™¤: {filename}")

                    # R2ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
                    if filename in r2_filenames:
                        remote_path = f"{folder_name}/{filename}"
                        delete_success = delete_from_r2(r2_client, remote_path, r2_bucket)
                        if delete_success:
                            logger.info(f"ğŸ—‘ï¸ R2å‰Šé™¤: {remote_path}")
            except Exception as e:
                logger.error(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ã‚¨ãƒ©ãƒ¼: {filename} - {e}")
                continue

    # RSSç”Ÿæˆ
    logger.info(f"ğŸ“„ feed.xml ç”Ÿæˆ: {folder_name}")
    rss_items = []

    # ç¾åœ¨ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ—¥ä»˜é †ï¼ˆæ–°ã—ã„é †ï¼‰ã«ã‚½ãƒ¼ãƒˆ
    mp3_files = [f for f in os.listdir(output_dir) if f.endswith(".mp3")]
    mp3_files.sort(reverse=True)  # æ–°ã—ã„é †

    max_rss_items = int(config['Settings'].get('max_rss_items', '30'))

    for filename in mp3_files:
        if len(rss_items) >= max_rss_items:
            break

        try:
            base = os.path.splitext(filename)[0]
            if "ï¼š" not in base:
                continue

            mmdd, raw_title = base.split("ï¼š", 1)
            title = raw_title.strip()
            today = datetime.strptime(mmdd, "%m-%d").replace(year=datetime.now().year)
            pubdate = email.utils.format_datetime(today)
            filepath = os.path.join(output_dir, filename)
            filesize = os.path.getsize(filepath)
            fileurl = f"{config['R2']['public_base_url']}/{folder_name}/{filename}"

            duration_sec = durations.get(filename, 0)
            h, m, s = duration_sec // 3600, (duration_sec % 3600) // 60, duration_sec % 60
            duration_str = f"{h:02}:{m:02}:{s:02}"

            item = f"""
    <item>
      <title>{title}</title>
      <enclosure url=\"{fileurl}\" length=\"{filesize}\" type=\"audio/mpeg\" />
      <guid>{fileurl}</guid>
      <pubDate>{pubdate}</pubDate>
      <itunes:duration>{duration_str}</itunes:duration>
    </item>"""
            rss_items.append(item)
        except Exception as e:
            logger.error(f"âš ï¸ RSSé …ç›®ã‚¨ãƒ©ãƒ¼: {filename} ({e})")
            continue

    rss_feed = f"""<?xml version=\"1.0\" encoding=\"UTF-8\"?>
<rss version=\"2.0\" xmlns:itunes=\"http://www.itunes.com/dtds/podcast-1.0.dtd\">
  <channel>
    <title>{display_name}</title>
    <link>{config['R2']['public_base_url']}/{folder_name}/</link>
    <description>{display_name} ã®éŸ³å£°Podcast</description>
    <language>ja</language>
    <itunes:category text="News"/>
    <lastBuildDate>{email.utils.format_datetime(datetime.utcnow())}</lastBuildDate>
    {''.join(rss_items)}
  </channel>
</rss>
"""

    with open(os.path.join(output_dir, "feed.xml"), "w", encoding="utf-8") as f:
        f.write(rss_feed)
    logger.info(f"âœ… RSSç”Ÿæˆå®Œäº†: {folder_name}")

    return folder_name

def main():
    try:
        logger.info("ğŸš€ YouTubeâ†’ãƒãƒƒãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¤‰æ› é–‹å§‹")

        # è¨­å®šèª­ã¿è¾¼ã¿
        config = load_config()

        # è¨­å®šã‹ã‚‰ä¸¦åˆ—å‡¦ç†æ•°ã‚’èª­ã¿è¾¼ã¿
        max_workers = int(config['Settings'].get('max_workers', '3'))
        max_yt_dlp = int(config['Settings'].get('max_yt_dlp_processes', '2'))

        # yt-dlpã®åŒæ™‚å®Ÿè¡Œæ•°åˆ¶é™ç”¨ã‚»ãƒãƒ•ã‚©ã‚’è¨­å®š
        global yt_dlp_semaphore
        yt_dlp_semaphore = threading.Semaphore(max_yt_dlp)

        # R2ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        r2_client = init_r2_client(config)

        # è¨­å®šã‹ã‚‰ãƒãƒ£ãƒ³ãƒãƒ«ã¨ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæƒ…å ±ã‚’å–å¾—
        channels = dict(config['Channels'].items())
        playlists = dict(config['Playlists'].items())

        # ä¸¦åˆ—å‡¦ç†ã§å„ç•ªçµ„ã‚’å‡¦ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            for folder_name, playlist_url in playlists.items():
                futures.append(executor.submit(process_program, (folder_name, playlist_url, config, r2_client)))

            # å®Œäº†ã‚’å¾…æ©Ÿ
            for future in concurrent.futures.as_completed(futures):
                try:
                    folder_name = future.result()
                    if folder_name:
                        logger.info(f"âœ… ç•ªçµ„å‡¦ç†å®Œäº†: {folder_name}")
                except Exception as e:
                    logger.error(f"âš ï¸ ç•ªçµ„å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿ: {e}")

        # Git pushï¼ˆfeed.xml ã®ã¿ï¼‰
        logger.info("\nğŸš€ GitHubã«pushä¸­...")
        
        ## ãƒªãƒã‚¸ãƒˆãƒªã®ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’å–å¾—
        repo_dir = os.path.dirname(os.path.dirname(os.path.dirname(script_dir)))
        
        git_commands = [
            ["git", "-C", repo_dir, "pull"],
            ["git", "-C", repo_dir, "add", "projects/podcast-converter/data/*/feed.xml"],
            ["git", "-C", repo_dir, "commit", "-m", "auto: update all feeds"],
            ["git", "-C", repo_dir, "push"]
        ]

        for cmd in git_commands:
            result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
            if result.returncode != 0:
                logger.error(f"âš ï¸ Gitã‚¨ãƒ©ãƒ¼: {' '.join(cmd)}")
                logger.error(result.stderr)
                break
            else:
                logger.info(f"âœ… {' '.join(cmd)} å®Œäº†")

        logger.info("ğŸ‰ å…¨å‡¦ç†å®Œäº†ï¼")

    except Exception as e:
        logger.critical(f"âŒ è‡´å‘½çš„ã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return 1

    return 0

if __name__ == "__main__":
    sys.exit(main())